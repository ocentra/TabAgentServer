//! Summarizer module - generates conversation summaries.
//!
//! This module creates Summary nodes for chats when enough new messages
//! have accumulated.

use crate::{WeaverContext, WeaverResult};
use common::{NodeId, EdgeId, models::{Chat, Edge, Node, Summary}};

/// Processes a chat update to potentially generate a summary.
///
/// Called when a chat has accumulated enough new messages since the last summary.
pub async fn on_chat_updated(
    context: &WeaverContext,
    chat_id: &str,
) -> WeaverResult<()> {
    log::debug!("Summarizer: Processing chat {}", chat_id);
    
    // Load the chat node
    let chat = match context.coordinator.conversations_active().get_node(chat_id)? {
        Some(Node::Chat(c)) => c,
        _ => {
            log::warn!("Chat {} not found for summarization", chat_id);
            return Ok(());
        }
    };
    
    // Get recent messages for the chat
    let messages = get_recent_messages(context, &chat).await?;
    
    if messages.is_empty() {
        log::debug!("No messages to summarize for chat {}", chat_id);
        return Ok(());
    }
    
    log::info!("Summarizing {} messages for chat {}", messages.len(), chat_id);
    
    // Generate summary via ML bridge
    let summary_text = context.ml_bridge.summarize(&messages).await
        .map_err(|e| crate::WeaverError::MlInference(e.to_string()))?;
    
    // Create Summary node
    let summary_id = format!("sum_{}", uuid::Uuid::new_v4());
    let now = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_millis() as i64;
    
    let summary = Summary {
        id: NodeId::from(summary_id.as_str()),
        chat_id: NodeId::from(chat_id),
        created_at: now,
        content: summary_text,
        message_ids: chat.message_ids.clone(), // Include all messages in summary
        embedding_id: None, // Will be generated by semantic_indexer
        metadata: serde_json::json!({
            "message_count": messages.len(),
        }),
    };
    
    // Store the summary
    context.coordinator.conversations_active().insert_node(&Node::Summary(summary))?;
    
    // Create CONTAINS_SUMMARY edge from chat to summary
    create_summary_edge(context, chat_id, &summary_id).await?;
    
    log::info!("Created summary {} for chat {}", summary_id, chat_id);
    
    Ok(())
}

/// Retrieves recent messages from a chat for summarization.
async fn get_recent_messages(
    context: &WeaverContext,
    chat: &Chat,
) -> WeaverResult<Vec<String>> {
    let mut messages = Vec::new();
    
    // Get the last N messages (up to 50)
    let message_ids: Vec<_> = chat.message_ids.iter()
        .rev()
        .take(50)
        .collect();
    
    for message_id in message_ids {
        if let Some(Node::Message(msg)) = context.coordinator.conversations_active().get_node(message_id.as_str())? {
            messages.push(msg.text_content);
        }
    }
    
    // Reverse to get chronological order
    messages.reverse();
    
    Ok(messages)
}

/// Creates a CONTAINS_SUMMARY edge from chat to summary.
async fn create_summary_edge(
    context: &WeaverContext,
    chat_id: &str,
    summary_id: &str,
) -> WeaverResult<()> {
    let edge_id = format!("edge_{}", uuid::Uuid::new_v4());
    let edge = Edge {
        id: EdgeId::from(edge_id.as_str()),
        from_node: NodeId::from(chat_id),
        to_node: NodeId::from(summary_id),
        edge_type: "CONTAINS_SUMMARY".to_string(),
        created_at: std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_millis() as i64,
        metadata: serde_json::json!({}),
    };
    
    context.coordinator.conversations_active().insert_edge(&edge)?;
    
    log::debug!("Created CONTAINS_SUMMARY edge: {} -> {}", chat_id, summary_id);
    
    Ok(())
}

