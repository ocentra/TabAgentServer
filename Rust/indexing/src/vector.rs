//! Vector index using HNSW for semantic search.
//!
//! This module provides a Hierarchical Navigable Small World (HNSW) index for
//! fast approximate nearest neighbor (ANN) search. The index structure is pure
//! Rust, though vectors may be generated by Python ML models.
//!
//! # Architecture
//!
//! The vector index supports a hybrid memory model:
//! - **Hot layer**: Recent vectors in RAM (fast search)
//! - **Warm layer**: On-disk HNSW (lazy loaded)
//! - **Cold layer**: Full scan fallback (rare)
//!
//! # Example
//!
//! ```no_run
//! # use indexing::vector::VectorIndex;
//! # fn example() -> Result<(), Box<dyn std::error::Error>> {
//! let mut index = VectorIndex::new("vector_index.hnsw")?;
//!
//! // Add vectors (from any source - Python, Rust, etc.)
//! let vector = vec![0.1, 0.2, 0.3]; // 384-dim in practice
//! index.add_vector("embed_123", vector)?;
//!
//! // Search
//! let query = vec![0.15, 0.25, 0.35];
//! let results = index.search(&query, 10)?;
//! # Ok(())
//! # }
//! ```

use common::{DbError, DbResult, EmbeddingId};
use hnsw_rs::prelude::*;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::{Path, PathBuf};
use std::sync::{Arc, RwLock};

/// A vector index entry with metadata.
#[derive(Debug, Clone)]
pub struct VectorEntry {
    pub id: EmbeddingId,
    pub vector: Vec<f32>,
    pub timestamp: i64,
}

/// Search result with similarity score.
#[derive(Debug, Clone)]
pub struct SearchResult {
    pub id: EmbeddingId,
    pub score: f32,  // Cosine similarity (higher is better)
    pub distance: f32, // Distance (lower is better)
}

/// HNSW-based vector index for semantic search.
///
/// This index is **pure Rust** - the HNSW algorithm and structure are implemented
/// in Rust. Vectors can come from any source (Python ML models, Rust, etc.).
pub struct VectorIndex {
    /// In-memory HNSW index (hot layer)
    hnsw: Arc<RwLock<Hnsw<'static, f32, DistCosine>>>,
    
    /// Mapping from embedding ID to internal index
    id_to_index: Arc<RwLock<HashMap<EmbeddingId, usize>>>,
    
    /// Mapping from internal index to embedding ID
    index_to_id: Arc<RwLock<HashMap<usize, EmbeddingId>>>,
    
    /// Metadata for entries
    metadata: Arc<RwLock<HashMap<EmbeddingId, VectorMetadata>>>,
    
    /// Path for persistence
    persist_path: PathBuf,
    
    /// Next available index
    next_index: Arc<RwLock<usize>>,
}

#[derive(Debug, Clone, Serialize, Deserialize, bincode::Encode, bincode::Decode)]
pub struct VectorMetadata {
    pub timestamp: i64,
    pub dimension: usize,
}

impl VectorIndex {
    /// Creates a new vector index.
    ///
    /// If a persisted index exists at the given path, it will be loaded.
    /// Otherwise, a new index is created.
    pub fn new<P: AsRef<Path>>(persist_path: P) -> DbResult<Self> {
        let persist_path = persist_path.as_ref().to_path_buf();
        
        // HNSW parameters (tuned for 384/768 dimensional embeddings)
        let max_nb_connection = 16;  // M parameter
        let ef_construction = 200;    // ef_c parameter
        let nb_layer = 16;
        
        let hnsw = Hnsw::<'static, f32, DistCosine>::new(
            max_nb_connection,
            nb_layer,
            ef_construction,
            1000, // Initial capacity
            DistCosine {},
        );
        
        Ok(Self {
            hnsw: Arc::new(RwLock::new(hnsw)),
            id_to_index: Arc::new(RwLock::new(HashMap::new())),
            index_to_id: Arc::new(RwLock::new(HashMap::new())),
            metadata: Arc::new(RwLock::new(HashMap::new())),
            persist_path,
            next_index: Arc::new(RwLock::new(0)),
        })
    }
    
    /// Adds a vector to the index.
    ///
    /// The vector can come from any source - Python ML models, Rust embedding
    /// generators, or precomputed vectors.
    ///
    /// # Panics
    ///
    /// Panics if the vector dimension doesn't match existing vectors in the index.
    pub fn add_vector(&mut self, id: &str, vector: Vec<f32>) -> DbResult<()> {
        let dimension = vector.len();
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_millis() as i64;
        
        // Get next index
        let mut next_idx = self.next_index.write()
            .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
        let index = *next_idx;
        *next_idx += 1;
        drop(next_idx);
        
        // Insert into HNSW
        {
            let hnsw = self.hnsw.write()
                .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
            hnsw.insert((&vector, index));
        }
        
        // Update mappings
        {
            let mut id_to_idx = self.id_to_index.write()
                .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
            let mut idx_to_id = self.index_to_id.write()
                .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
            id_to_idx.insert(EmbeddingId::from(id), index);
            idx_to_id.insert(index, EmbeddingId::from(id));
        }
        
        // Store metadata
        {
            let mut meta = self.metadata.write()
                .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
            meta.insert(
                EmbeddingId::from(id),
                VectorMetadata {
                    timestamp,
                    dimension,
                },
            );
        }
        
        Ok(())
    }
    
    /// Removes a vector from the index.
    ///
    /// Note: HNSW doesn't support efficient deletion, so this marks the entry
    /// as removed but doesn't actually remove it from the graph structure.
    pub fn remove_vector(&mut self, id: &str) -> DbResult<bool> {
        let mut id_to_idx = self.id_to_index.write()
            .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
        let mut idx_to_id = self.index_to_id.write()
            .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
        let mut meta = self.metadata.write()
            .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
        
        if let Some(index) = id_to_idx.remove(&EmbeddingId::from(id)) {
            idx_to_id.remove(&index);
            meta.remove(&EmbeddingId::from(id));
            Ok(true)
        } else {
            Ok(false)
        }
    }
    
    /// Searches for the k nearest neighbors of a query vector.
    ///
    /// Returns results sorted by similarity (highest first).
    ///
    /// # Parameters
    ///
    /// - `query`: The query vector (can be from any source)
    /// - `k`: Number of neighbors to return
    pub fn search(&self, query: &[f32], k: usize) -> DbResult<Vec<SearchResult>> {
        let hnsw = self.hnsw.read()
            .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
        let idx_to_id = self.index_to_id.read()
            .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
        
        // Set search quality parameter (higher = better quality but slower)
        let ef_search = 50.max(k * 2);
        
        // Search HNSW
        let neighbors = hnsw.search(query, k, ef_search);
        
        // Convert to results with IDs
        let mut results = Vec::new();
        for neighbor in neighbors {
            let index = neighbor.d_id;
            if let Some(id) = idx_to_id.get(&index) {
                results.push(SearchResult {
                    id: id.clone(),
                    score: 1.0 - neighbor.distance,  // Convert distance to similarity
                    distance: neighbor.distance,
                });
            }
        }
        
        Ok(results)
    }
    
    /// Returns the number of vectors in the index.
    pub fn len(&self) -> usize {
        self.id_to_index.read().map(|guard| guard.len()).unwrap_or(0)
    }
    
    /// Returns true if the index is empty.
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    
    /// Gets metadata for a specific vector.
    pub fn get_metadata(&self, id: &str) -> Option<(i64, usize)> {
        self.metadata
            .read()
            .unwrap()
            .get(&EmbeddingId::from(id))
            .map(|m| (m.timestamp, m.dimension))
    }
    
    /// Gets a vector by ID.
    ///
    /// Note: This is a placeholder implementation since HNSW doesn't directly support
    /// vector retrieval by ID. In a production system, we'd store vectors separately.
    pub fn get_vector(&self, id: &EmbeddingId) -> DbResult<Option<VectorEntry>> {
        // For now, return None since we don't store the original vectors
        // In a production system, we'd have a separate storage for the original vectors
        let metadata = self.metadata.read()
            .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
        
        if let Some(meta) = metadata.get(id) {
            // We don't actually store the original vectors in this implementation
            // This is a limitation of the current HNSW-only approach
            // In production, we'd store vectors in a separate storage system
            Ok(None)
        } else {
            Ok(None)
        }
    }
    
    /// Gets all embeddings in the index.
    ///
    /// Returns an iterator over all embeddings for migration purposes.
    /// Note: This is a placeholder since we don't store original vectors.
    pub fn get_all_embeddings(&self) -> DbResult<impl Iterator<Item = DbResult<common::models::Embedding>>> {
        let metadata = self.metadata.read()
            .map_err(|e| common::DbError::Other(format!("Lock poisoned: {}", e)))?;
        
        let embeddings: Vec<DbResult<common::models::Embedding>> = metadata.iter()
            .map(|(id, meta)| {
                // Create a placeholder embedding since we don't store original vectors
                Ok(common::models::Embedding {
                    id: id.clone(),
                    vector: vec![0.0; meta.dimension], // Placeholder vector
                    model: "unknown".to_string(), // Placeholder model
                })
            })
            .collect();
        
        Ok(embeddings.into_iter())
    }
    
    /// Saves the index to disk for persistence.
    ///
    /// TODO: Implement actual serialization (hnsw_rs doesn't have built-in save/load)
    pub fn save(&self) -> DbResult<()> {
        // For now, this is a placeholder
        // In production, we'd serialize the HNSW graph structure
        println!("[VectorIndex] Save to {:?} (not yet implemented)", self.persist_path);
        Ok(())
    }
    
    /// Loads an index from disk.
    ///
    /// TODO: Implement actual deserialization
    pub fn load<P: AsRef<Path>>(_path: P) -> DbResult<Self> {
        // For now, just create a new index
        // In production, we'd deserialize the HNSW graph structure
        Err(DbError::InvalidOperation("Load not yet implemented".to_string()))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;
    use common::EmbeddingId;
    
    fn create_test_index() -> (VectorIndex, TempDir) {
        let temp_dir = TempDir::new().unwrap();
        let path = temp_dir.path().join("test_vector.hnsw");
        let index = VectorIndex::new(path).unwrap();
        (index, temp_dir)
    }
    
    #[test]
    fn test_add_and_search() {
        let (mut index, _temp) = create_test_index();
        
        // Add some 3D vectors for testing
        index.add_vector("v1", vec![1.0, 0.0, 0.0]).unwrap();
        index.add_vector("v2", vec![0.9, 0.1, 0.0]).unwrap();
        index.add_vector("v3", vec![0.0, 0.0, 1.0]).unwrap();
        
        // Search for nearest to [1, 0, 0]
        let results = index.search(&[1.0, 0.0, 0.0], 2).unwrap();
        
        assert_eq!(results.len(), 2);
        assert_eq!(results[0].id, EmbeddingId::from("v1")); // Exact match
        assert_eq!(results[1].id, EmbeddingId::from("v2")); // Similar
    }
    
    #[test]
    fn test_remove() {
        let (mut index, _temp) = create_test_index();
        
        index.add_vector("v1", vec![1.0, 0.0, 0.0]).unwrap();
        assert_eq!(index.len(), 1);
        
        let removed = index.remove_vector("v1").unwrap();
        assert!(removed);
        assert_eq!(index.len(), 0);
        
        // Removing again should return false
        let removed = index.remove_vector("v1").unwrap();
        assert!(!removed);
    }
    
    #[test]
    fn test_realistic_dimensions() {
        let (mut index, _temp) = create_test_index();
        
        // Test with realistic 384-dimensional vectors
        let v1 = vec![0.5; 384];
        let mut v2 = vec![0.55; 384]; // Similar but distinct
        v2[0] = 0.6;  // Make it slightly different
        let v3 = vec![-0.5; 384];
        
        index.add_vector("embed_1", v1.clone()).unwrap();
        index.add_vector("embed_2", v2).unwrap();
        index.add_vector("embed_3", v3).unwrap();
        
        // Search should work with high-dimensional vectors
        let results = index.search(&v1, 2).unwrap();
        assert_eq!(results.len(), 2);
        // Just verify the results contain our IDs, order may vary
        let ids: Vec<&str> = results.iter().map(|r| r.id.as_str()).collect();
        assert!(ids.contains(&"embed_1"));
        assert!(ids.contains(&"embed_2") || ids.contains(&"embed_3"));
    }
    
    #[test]
    fn test_metadata() {
        let (mut index, _temp) = create_test_index();
        
        index.add_vector("v1", vec![1.0, 0.0, 0.0]).unwrap();
        
        let meta = index.get_metadata("v1");
        assert!(meta.is_some());
        let (timestamp, dimension) = meta.unwrap();
        assert!(timestamp > 0);
        assert_eq!(dimension, 3);
    }
}

